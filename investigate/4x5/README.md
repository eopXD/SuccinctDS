# investigation on 4x5 result data


## Concat all Data

I concatenated all decompressed parts into one.
File size is `7542669312 Byte` = `7.02466G`.

The following investigation will be on the concated file.

## Bit: 45 ~ 50

```
00000: 000000: 	920009714
00001: 000001: 	2520838
00002: 000010: 	3212196
00003: 000011: 	1793579
00004: 000100: 	2752125
00005: 000101: 	3382956
00006: 000110: 	5030932
00007: 000111: 	4131324
00008: 001000: 	0
00009: 001001: 	0
00010: 001010: 	0
00011: 001011: 	0
00012: 001100: 	0
00013: 001101: 	0
00014: 001110: 	0
00015: 001111: 	0
00016: 010000: 	0
00017: 010001: 	0
00018: 010010: 	0
00019: 010011: 	0
00020: 010100: 	0
00021: 010101: 	0
00022: 010110: 	0
00023: 010111: 	0
00024: 011000: 	0
00025: 011001: 	0
00026: 011010: 	0
00027: 011011: 	0
00028: 011100: 	0
00029: 011101: 	0
00030: 011110: 	0
00031: 011111: 	0
00032: 100000: 	0
00033: 100001: 	0
00034: 100010: 	0
00035: 100011: 	0
00036: 100100: 	0
00037: 100101: 	0
00038: 100110: 	0
00039: 100111: 	0
00040: 101000: 	0
00041: 101001: 	0
00042: 101010: 	0
00043: 101011: 	0
00044: 101100: 	0
00045: 101101: 	0
00046: 101110: 	0
00047: 101111: 	0
00048: 110000: 	0
00049: 110001: 	0
00050: 110010: 	0
00051: 110011: 	0
00052: 110100: 	0
00053: 110101: 	0
00054: 110110: 	0
00055: 110111: 	0
00056: 111000: 	0
00057: 111001: 	0
00058: 111010: 	0
00059: 111011: 	0
00060: 111100: 	0
00061: 111101: 	0
00062: 111110: 	0
00063: 111111: 	0
total blocks: 942833664
H0 entropy: 0.23081
```

## Bit: 51 ~ 52

```
00000: 00: 	299259214
00001: 01: 	28384923
00002: 10: 	615189527
00003: 11: 	0
total blocks: 942833664
H0 entropy: 1.07956
```

## Bit: 45 ~ 52

```
00000: 00000000: 	299259214
00001: 00000001: 	5560973
00002: 00000010: 	615189527
00003: 00000011: 	0
00004: 00000100: 	0
00005: 00000101: 	2520838
00006: 00000110: 	0
00007: 00000111: 	0
00008: 00001000: 	0
00009: 00001001: 	3212196
00010: 00001010: 	0
00011: 00001011: 	0
00012: 00001100: 	0
00013: 00001101: 	1793579
00014: 00001110: 	0
00015: 00001111: 	0
00016: 00010000: 	0
00017: 00010001: 	2752125
00018: 00010010: 	0
00019: 00010011: 	0
00020: 00010100: 	0
00021: 00010101: 	3382956
00022: 00010110: 	0
00023: 00010111: 	0
00024: 00011000: 	0
00025: 00011001: 	5030932
00026: 00011010: 	0
00027: 00011011: 	0
00028: 00011100: 	0
00029: 00011101: 	4131324
00030: 00011110: 	0
00031: 00011111: 	0
00032: 00100000: 	0
00033: 00100001: 	0
00034: 00100010: 	0
00035: 00100011: 	0
00036: 00100100: 	0
00037: 00100101: 	0
00038: 00100110: 	0
00039: 00100111: 	0
00040: 00101000: 	0
00041: 00101001: 	0
00042: 00101010: 	0
00043: 00101011: 	0
00044: 00101100: 	0
00045: 00101101: 	0
00046: 00101110: 	0
00047: 00101111: 	0
00048: 00110000: 	0
00049: 00110001: 	0
00050: 00110010: 	0
00051: 00110011: 	0
00052: 00110100: 	0
00053: 00110101: 	0
00054: 00110110: 	0
00055: 00110111: 	0
00056: 00111000: 	0
00057: 00111001: 	0
00058: 00111010: 	0
00059: 00111011: 	0
00060: 00111100: 	0
00061: 00111101: 	0
00062: 00111110: 	0
00063: 00111111: 	0
00064: 01000000: 	0
00065: 01000001: 	0
00066: 01000010: 	0
00067: 01000011: 	0
00068: 01000100: 	0
00069: 01000101: 	0
00070: 01000110: 	0
00071: 01000111: 	0
00072: 01001000: 	0
00073: 01001001: 	0
00074: 01001010: 	0
00075: 01001011: 	0
00076: 01001100: 	0
00077: 01001101: 	0
00078: 01001110: 	0
00079: 01001111: 	0
00080: 01010000: 	0
00081: 01010001: 	0
00082: 01010010: 	0
00083: 01010011: 	0
00084: 01010100: 	0
00085: 01010101: 	0
00086: 01010110: 	0
00087: 01010111: 	0
00088: 01011000: 	0
00089: 01011001: 	0
00090: 01011010: 	0
00091: 01011011: 	0
00092: 01011100: 	0
00093: 01011101: 	0
00094: 01011110: 	0
00095: 01011111: 	0
00096: 01100000: 	0
00097: 01100001: 	0
00098: 01100010: 	0
00099: 01100011: 	0
00100: 01100100: 	0
00101: 01100101: 	0
00102: 01100110: 	0
00103: 01100111: 	0
00104: 01101000: 	0
00105: 01101001: 	0
00106: 01101010: 	0
00107: 01101011: 	0
00108: 01101100: 	0
00109: 01101101: 	0
00110: 01101110: 	0
00111: 01101111: 	0
00112: 01110000: 	0
00113: 01110001: 	0
00114: 01110010: 	0
00115: 01110011: 	0
00116: 01110100: 	0
00117: 01110101: 	0
00118: 01110110: 	0
00119: 01110111: 	0
00120: 01111000: 	0
00121: 01111001: 	0
00122: 01111010: 	0
00123: 01111011: 	0
00124: 01111100: 	0
00125: 01111101: 	0
00126: 01111110: 	0
00127: 01111111: 	0
00128: 10000000: 	0
00129: 10000001: 	0
00130: 10000010: 	0
00131: 10000011: 	0
00132: 10000100: 	0
00133: 10000101: 	0
00134: 10000110: 	0
00135: 10000111: 	0
00136: 10001000: 	0
00137: 10001001: 	0
00138: 10001010: 	0
00139: 10001011: 	0
00140: 10001100: 	0
00141: 10001101: 	0
00142: 10001110: 	0
00143: 10001111: 	0
00144: 10010000: 	0
00145: 10010001: 	0
00146: 10010010: 	0
00147: 10010011: 	0
00148: 10010100: 	0
00149: 10010101: 	0
00150: 10010110: 	0
00151: 10010111: 	0
00152: 10011000: 	0
00153: 10011001: 	0
00154: 10011010: 	0
00155: 10011011: 	0
00156: 10011100: 	0
00157: 10011101: 	0
00158: 10011110: 	0
00159: 10011111: 	0
00160: 10100000: 	0
00161: 10100001: 	0
00162: 10100010: 	0
00163: 10100011: 	0
00164: 10100100: 	0
00165: 10100101: 	0
00166: 10100110: 	0
00167: 10100111: 	0
00168: 10101000: 	0
00169: 10101001: 	0
00170: 10101010: 	0
00171: 10101011: 	0
00172: 10101100: 	0
00173: 10101101: 	0
00174: 10101110: 	0
00175: 10101111: 	0
00176: 10110000: 	0
00177: 10110001: 	0
00178: 10110010: 	0
00179: 10110011: 	0
00180: 10110100: 	0
00181: 10110101: 	0
00182: 10110110: 	0
00183: 10110111: 	0
00184: 10111000: 	0
00185: 10111001: 	0
00186: 10111010: 	0
00187: 10111011: 	0
00188: 10111100: 	0
00189: 10111101: 	0
00190: 10111110: 	0
00191: 10111111: 	0
00192: 11000000: 	0
00193: 11000001: 	0
00194: 11000010: 	0
00195: 11000011: 	0
00196: 11000100: 	0
00197: 11000101: 	0
00198: 11000110: 	0
00199: 11000111: 	0
00200: 11001000: 	0
00201: 11001001: 	0
00202: 11001010: 	0
00203: 11001011: 	0
00204: 11001100: 	0
00205: 11001101: 	0
00206: 11001110: 	0
00207: 11001111: 	0
00208: 11010000: 	0
00209: 11010001: 	0
00210: 11010010: 	0
00211: 11010011: 	0
00212: 11010100: 	0
00213: 11010101: 	0
00214: 11010110: 	0
00215: 11010111: 	0
00216: 11011000: 	0
00217: 11011001: 	0
00218: 11011010: 	0
00219: 11011011: 	0
00220: 11011100: 	0
00221: 11011101: 	0
00222: 11011110: 	0
00223: 11011111: 	0
00224: 11100000: 	0
00225: 11100001: 	0
00226: 11100010: 	0
00227: 11100011: 	0
00228: 11100100: 	0
00229: 11100101: 	0
00230: 11100110: 	0
00231: 11100111: 	0
00232: 11101000: 	0
00233: 11101001: 	0
00234: 11101010: 	0
00235: 11101011: 	0
00236: 11101100: 	0
00237: 11101101: 	0
00238: 11101110: 	0
00239: 11101111: 	0
00240: 11110000: 	0
00241: 11110001: 	0
00242: 11110010: 	0
00243: 11110011: 	0
00244: 11110100: 	0
00245: 11110101: 	0
00246: 11110110: 	0
00247: 11110111: 	0
00248: 11111000: 	0
00249: 11111001: 	0
00250: 11111010: 	0
00251: 11111011: 	0
00252: 11111100: 	0
00253: 11111101: 	0
00254: 11111110: 	0
00255: 11111111: 	0
total blocks: 942833664
H0 entropy: 1.1674
```

## Entropy and Expected Memory Usage

Lets recall the definition of entropy. Entropy right here can be understood as average lower bound amount of data to represent an incident given incident set, and given the probability of the incident's occurence.

### 4x5 Data

Lets examine on the outputs above. There are a total of 942833664 (~900M) blocks of `4x5` data.

- `45~50` bit: $H_0 = 0.23081$ (with value zero occuring a lot)
- `51~52` bit: $H_0 = 1.07956$
- `45~52` bit: $H_0 = 1.1674$

This means the average bit to represent an incident occurence given the event set and its probability of occurence.

Multiply by the total amount (900M) we need to save, we can calculate our optimal data amount to save the data:

- `45~50` bit: $H_0\ \times\ 900M = 207.729M$ 
- `51~52` bit: $H_0\ \times\ 900M = 971.604M$ 
- `45~52` bit: $H_0\ \times\ 900M = 1050.66M$

Compression rate:

- `45~50` bit: $207.729\ \div\ 7.02466G = 2.888\%$ 
- `51~52` bit: $971.604\ \div\ 7.02466G = 13.507\%$ 
- `45~52` bit: $1050.66\ \div\ 7.02466G = 14.606\%$

This is the optimal compression rate, as we know need to support rank operation, there will be indeed some overheads.

### 4x5 Data on Wavelet Tree


For RRR bitvector, we would need a $1.16$ the size of the original bit vector size to support rank in constant time. By Huff-man wavelet tree, the total bit of representing the whole data will be its $H_0$, therefore the original size of the bitvector shall be the numbers calculated above.

Then multiplying by $116\%$, we get our expected wavelet tree size:

- `45~50` bit: $H_0\ \times\ 900M \times 116\% =  240.955M$ 
- `51~52` bit: $H_0\ \times\ 900M \times 116\% = 1127.06M$ 
- `45~52` bit: $H_0\ \times\ 900M \times 116\% = 1218.77M$

Compression rate:

- `45~50` bit: $240.955\ \div\ 7.02466G = 3.349\%$ 
- `51~52` bit: $1127.06\ \div\ 7.02466G = 15.668\%$ 
- `45~52` bit: $1218.77\ \div\ 7.02466G = 16.943\%$

## Experiment Results - 45-50 bit

```
eopXD@white:/tmp2/b04705001/SuccinctDS/investigate/src$ ./test.try_compress
input filename (absolute path): /tmp2/b04705001/4x5/decompressed/concat_all.decode0


file: /tmp2/b04705001/4x5/decompressed/concat_all.decode0
filesize: 942833664 0.878082G
[wt] stream mode
[wt_huff] stream mode constructor activated
get_freq: 1.70342 seconds
[huff_wt] empirical frequency
	00000000:920009714
	00000010:3212196
	00000001:2520838
	00000111:4131324
	00000110:5030932
	00000101:3382956
	00000100:2752125
	00000011:1793579
[huff_wt] node merge...
construct_tree: 0.126502 seconds
[wt_huff] Huffman code generated
	00000000: 0
	00000001: 1110
	00000010: 1010
	00000011: 1111
	00000100: 1011
	00000101: 1001
	00000110: 110
	00000111: 1000

**************************************************
gen_code: 0.000123 seconds
fill_data: 5.19761 seconds
total: 7.02775 seconds


wavelet tree:
mem_used: :126864583 0.118152G
ratio: 0.134557

after support_rank():
mem_used: :147888099 0.137732G
ratio: 0.156855

after rank: 1.16572
```

Now the amount of overhead is correct to the theoretical calcualtions.

## Experiment Results - 45-52 bit

```
input filename (absolute path): /tmp2/b04705001/4x5/decompressed/concat_all.decode1


file: /tmp2/b04705001/4x5/decompressed/concat_all.decode1
filesize: 942833664 0.878082G
[wt] stream mode
[wt_huff] stream mode constructor activated
get_freq: 2.36262 seconds
[huff_wt] empirical frequency
	00000010:615189527
	00000000:299259214
	00001001:3212196
	00000101:2520838
	00000001:5560973
	00011101:4131324
	00011001:5030932
	00010101:3382956
	00010001:2752125
	00001101:1793579
[huff_wt] node merge...
construct_tree: 0.170734 seconds
[wt_huff] Huffman code generated
	00000000: 10
	00000001: 1111
	00000010: 0
	00000101: 110010
	00001001: 11100
	00001101: 110011
	00010001: 11101
	00010101: 11011
	00011001: 11000
	00011101: 11010

**************************************************
gen_code: 8.4e-05 seconds
fill_data: 7.29609 seconds
total: 9.82961 seconds


wavelet tree:
mem_used: :170387519 0.158686G
ratio: 0.180719

after support_rank():
mem_used: :198680337 0.185035G
ratio: 0.210727

after rank: 1.16605
```

Now the amount of overhead is correct to the theoretical calcualtions.